<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" type="text/css" href="/css/linotype.css" />
    <script type="text/javascript" src="/js/d3.js"></script>
    <script type="text/javascript" src="/js/jquery-1.6.2.min.js"></script>
    <title>Aaron's Digital Wastebook - Aaron's Digital Wastebook</title>
  </head>

  <body>
    <script type="text/javascript" src="http://mathjax.connectmv.com/MathJax.js"></script>
    <link rel="shortcut icon" href="/images/4color.png" />
    <div id="doc" class="yui-t6"> 
      <div id="hd"> 
	<ul class="path"> 
	  <li><a href="/index.html">Home</a></li> 
	  
	  
	  <!--     <li><a href="/{}"></a></li>  -->
	  <li class="current">Aaron's Digital Wastebook</li> 
	</ul> 	
	<h1>Aaron's Digital <br> Wastebook</h1> 
	<!--<h2>in Aaron's Digital Wastebook</h2> -->
      </div> 
      <div id="bd">
        <div id="yui-main"> 
          <div id="body" class="yui-b"> 	   
	    

<div id="main">
     <!--
	<div>
	  <h1>Recent Posts</h1>
	</div>
 -->      
  <ul class="posts">
    
    <div class=titlelisting>
      <!--<div class=date>-->09 Jul 2011<!--</div>-->
&nbsp&nbsp&nbsp&nbsp<a href="/blog/2011/07/09/candlestick-plots-in-d3.html"> candlestick plots in d3</a> <!--</h2>-->
      <!--<h2>-->

     </div>
    <br>
    <!-- <p>So, for a while now I’ve been using <a href="http://mbostock.github.com/protovis/">protovis</a> for visualizing data related to search quality (at <a href="http://www.etsy.com">work</a>). Last week I was working on tweaking some plots, and had to check some documentation, and I saw the notice on the protovis main page that it’s no longer under active development, and their team is now focused on <a href="http://mbostock.github.com/d3/">d3</a>, a library which I had only looked at but never tried before. So, I figured I’d give it a whirl and work with it a bit before trying to buy the time to port all my protovis code at work to d3. It has a similar feel to working in protovis, but protovis “marks” are supplanted by actual svg elements. Here’s a candlestick chart of the AMZN stock price for the past few weeks : </p>

<div id="chart"></div>

<p>Also, <a href="/blog/candlestick.html#GOOG">here’s</a> a larger form of it (but for Google data).</p>

<script type="text/javascript" src="/js/candlestick.js"></script>

<script type="text/javascript" src="/js/fetchstockdata.js"></script>

<script type="text/javascript">
 var width = 500;
 var height = 300;
 $(document).ready(fetchData);
</script>

 -->
    
    <div class=titlelisting>
      <!--<div class=date>-->15 Jan 2011<!--</div>-->
&nbsp&nbsp&nbsp&nbsp<a href="/blog/2011/01/15/cellular-automata.html"> cellular automata!</a> <!--</h2>-->
      <!--<h2>-->

     </div>
    <br>
    <!-- <p>Today I got bored, so I decided to make pretty pictures of the outputs of cellular automata. The code is <a href="https://gist.github.com/781483">here</a>.</p>

<p>The code was pretty simple to write (although I don’t write much python so I’m sure there’s a more elegant way to do this) and it’s very simple to use – just pass in the image dimensions you want out, and the <a href="http://en.wikipedia.org/wiki/Wolfram_code">wolfram code</a> of the 1D cellular automata you want to use. But it occured to me, that if <a href="http://en.wikipedia.org/wiki/Rule_110">Rule 110</a> is Turing complete (and apparently it is), then in a way, this is the fastest I’ve ever written a virtual machine! This is also probably the most inefficient, useless-virtual machine I could easily write, and in this case it happens to run on a random input, but whatever. It makes pretty pictures!</p>

<p>Rule 110 :</p>

<p><img src="http://farm6.static.flickr.com/5168/5359009600_fcaaa6ba6c.jpg" alt="Rule 110" title="Rule 110" /></p>

<p>Rule 30 :</p>

<p><img src="http://farm6.static.flickr.com/5004/5358395321_5cc92cf6d7.jpg" alt="Rule 30" title="Rule 30" /></p>

<p>P.S. On the relocating to NYC front : I’ve been here a couple of weeks now. It`s cold, but busy and cool.  Etsy is kinda awesome, both on a people front, and on a technical front (although search is more than a little broken; I have to work on that).</p>

 -->
    
    <div class=titlelisting>
      <!--<div class=date>-->16 Dec 2010<!--</div>-->
&nbsp&nbsp&nbsp&nbsp<a href="/blog/2010/12/16/new-beginnings.html"> SFO -> JFK</a> <!--</h2>-->
      <!--<h2>-->

     </div>
    <br>
    <!-- <p>Today is my last day working for A9; I’m leaving on vacation for two weeks, and beginning in January, I’ll be working for Etsy in NYC.</p>

<p>A9 was my first job out of college, and I’m grateful for all the opportunities I’ve had to work with and learn from a great team of engineers. </p>
 -->
    
    <div class=titlelisting>
      <!--<div class=date>-->02 Dec 2010<!--</div>-->
&nbsp&nbsp&nbsp&nbsp<a href="/blog/2010/12/02/hello-appengine.html"> Hello appengine</a> <!--</h2>-->
      <!--<h2>-->

     </div>
    <br>
    <!-- <p>Just a quick note : I had initially started this blog on github pages, and written a single substantive post before forgetting about it for an extended period. I’m attempting to restart my efforts, this time deciding to move to google appengine. The static content makes it a good fit for appengine, which offers more freedom and flexibility than github pages, where I could never get latex images to work. Also, with the new home I’m also dropping the old name (now expunged).</p>
 -->
    
    <div class=titlelisting>
      <!--<div class=date>-->07 Feb 2010<!--</div>-->
&nbsp&nbsp&nbsp&nbsp<a href="/blog/2010/02/07/machine-learning-is-not-magic.html"> Machine learning is not magic!</a> <!--</h2>-->
      <!--<h2>-->

     </div>
    <br>
    <!-- <p>A lot of machine learning has to do with learning functions.  We can generally think of learning these functions as either doing regression when the output variable of the function is a numerical value, or doing categorization when the dependent variable is discrete without any real ordering.  For the case of numerical dependent variables, the tutorial/textbook/lecture presentation tend to be “we have a univariate function $f$ where for some set of data $x<em>1 \ldots x_n$ we know the values $f(x</em>1) \ldots f(x_n)$.  Now given these $x$ we get univariate function $\hat{f}$ by $\ldots$”.  Then you show them the results of a bunch of reasonable approaches thrown at the problem, and they all look okay at the beginning, and pretty good by the end. </p>

<p>From the perspective of merely giving people an understanding of what’s going on in the algorithms, this approach is fine.  But I think it introduces a problem where people think these approaches are more powerful than they are.  The simple “works” for several reasons which may not be true of real applications :
- The function $f$ is simple (but not too simple), and often real-world processes which create data will be much more complicated
- The function $f$ is solely informed by the values in the data, but in real life you may be missing valuable data
- The dimension is small, so there’s enough data to go around.  When the dimension is high for many of the points you try to make predictions about, there will be no observed data point nearby to help you.</p>

<p>My first thought was to try to provide a category of examples where many strategies will fail – but this isn’t particularly interesting (e.g. provide too few data points and have a function with some narrow peaks, ridges or valleys).  Instead, I thought it would be fun to work with images.  Images can be cast as functions where $x$ is just the location of a pixel and $y$ is that pixel’s color.  This is fun for me because I don’t have any real experience working with image data – just getting the data into a form I could work with was new territory (I’m pretty sure I did it wrong; maybe a machine vision or image processing person will correct me someday).  It’s also beneficial to the reader in that people are intuitively able to understand the impact of providing more or less data, and people can easily understand the importance of domain knowledge which is beyond the grasp of the algorithm.</p>

<p>Before going any further, first let me give due credit to <a href="http://www.cs.wlu.edu/~levy/software/kd/" title="java KD-tree">the java KD-tree</a> I used for this.</p>

<p><img src="http://farm5.static.flickr.com/4015/4335461359_4390eec794_b.jpg" alt="Me at the Louvre, summer 2009" title="foo" /></p>

<p>In the above image, going left to right, you see the results of doing plain Nearest Neighbor, K Nearest Neighbor (with $k=3$) and K Nearest Neighbor with some smoothing (In a subsequent post, I want to do a Gaussian process/regression tack, and maybe some other mixture scheme).  And of course, top to bottom represents more to less data.  In particular, in each case I walked over the whole picture and included each pixel with some probability $p$, where in the top row $p = 0.1 * 2^{-7}$ and in the bottom row $p = 0.1$, and each row in between differs from those above and below by a factor of two.  Then for all non-sampled points, we try to guess the associated value given the sampled points, and those predictions, together with the sampled data are what you see displayed.  To be fair, each image is actually treated basically as three functions, one each for red, green and blue channels, and I’ve just remixed them for ease of presentation.</p>

<p>With the image above, I want to make a few points:</p>

<h3 id="our-models-are-wrong">Our models are wrong.</h3>

<p>Okay, so not necessarily always. Sometimes our data actually works according to a clean model – maybe a robot is navigating with distance sensors that really do have normal noise, for instance. But for Netflix and your credit card company and everyone trying to do inference using data that comes from people, our model is probably wrong.  </p>

<p>When a human looks at the pictures on the bottom row, they’re bringing a life’s worth of domain knowledge to the table to understand it.  It’s not just a map of (x,y) pairs to (r, g, b) values; it’s a kid standing in front of a statue.  But the simple nearest neighbor model, and the fancy Dirichlet mixture model, or some modified Ising model that make a straight-forward effort to just learn this as a picture are poor in that they don’t have a concept of this function being a 2d image of a 3d world where solid objects are seen under light, let alone concepts of sphinxes or tourists or hair or eyes.</p>

<p>A while ago I worked on what we called a “click model”.  Of course, I can’t go into details, but at the high level, if a user searches for something, and gets back a list of results and clicks on only one of them, there’s a tricky inference process about how this observation informs our understanding of the relevance of each of the returned results to the given query.  But really, you’re trying to write a model of user behavior, and inevitably there are a huge number of factors which affect that behavior which your system can’t consider.</p>

<h3 id="machine-learning-cant-aspire-to-be-magic">Machine learning can’t aspire to be magic.</h3>

<p>It’s just common sense.  A lot of people who have an idea of what machine learning is, but who haven’t actually worked on it much (and even some who have) tend to strongly over-estimate its powers.  But the bottom line is sometimes there simply isn’t enough data to really learn the underlying material.  No matter how smart your algorithms or your human visual system, given the very small amount of data in the top row of images, there’s no realistic way that you could really ‘learn’ what’s going on in the rest of the picture.  </p>

<p>Of course, the opposite is also true.  In the event that one can get measurements (or whatever) of a significant portion of the population as the observed data, it can be possible for even simple algorithms with no representation of the complex structure underlying the data (as in the bottom row of pictures above). Don’t get me wrong – different algorithms will fare better or worse, but they can all be in the same ballpark.  Above, if we were to evaluate the error of predicted RGB values from the true values of the original picture, we would see that the smoothed KNN approach is consistently superior to the KNN approach which is consistently superior to the single nearest neighbor approach.  But looking at the bottom row of pictures, does it really matter that much?</p>

<p>From the above two points, it would be tempting to say that supervised machine learning, and tasks like function learning or classification only can make meaningful improvements in some Goldilocks space of problems where where have enough data, but not too much.  But of course, what this misses is that how much data you have is relative to how big your space is, which is dependent on how you decide to represent your problem.</p>

<table>
  <tbody>
    <tr>
      <td>For instance, a language model trained on a bunch of sentences can really think of itself as having data dimension is $</td>
      <td>V</td>
      <td>^l$ where $V$ is the vocabulary size and $l$ is the longest sentence.  However an $n$-gram language model operates by picking some $n &lt; l$ and reconfiguring its data to be points of dimension $</td>
      <td>V</td>
      <td>^n$, and instead of predicting the next word given the whole previous part of the sentence, it can just predict given the last $n$ words.</td>
    </tr>
  </tbody>
</table>

<p><em>This</em> is how machine learning really advances – by reconsidering ways that problems can be represented.</p>
 -->
    
    <div class=titlelisting>
      <!--<div class=date>-->06 Feb 2010<!--</div>-->
&nbsp&nbsp&nbsp&nbsp<a href="/blog/2010/02/06/firstpost.html"> Hello World!</a> <!--</h2>-->
      <!--<h2>-->

     </div>
    <br>
    <!-- <h2 id="introduction-hello-world">Introduction (hello, world)</h2>

<p>I’m Aaron.  A while ago, I graduated from UC Berkeley with a degree in Cognitive Science, and started work as a software engineer doing search analytics at A9 in Palo Alto.  I’m interested in machine learning and in particular in the directions that Bayesian nonparametrics and work on stochastic/probabilistic programming are going.  When I’m not focused on technical issues, I like eating, reading (vegetarian/vegan) food blogs, and neglecting my piano.</p>

<h2 id="motivation">Motivation</h2>

<p>I’m starting the blog because I can’t stand to have all my coding be at work.  This practice causes lots of obvious frustrations:
* I conflate my frustration with work with my frustration with programming, and am starting to lose sight of the fun in playing with code
* I don’t get to talk about any of my projects with the outside world.  Because A9 doesn’t have a public facing service, many people think it’s either dead, or one of the projects that Bezos doesn’t have the heart to kill.  This means that if I don’t have something other than A9 to which I can tie my professional/technical name and reputation, I may be seen as a poor engineer at a useless, irrelevant company.
* My work projects aren’t playful.  Because our data is so big, many fun things become impractical.  Because our schedule is so tight, there’s relatively little room for exploration (or at least not as much as I’d like).<br />
* My projects don’t help me learn.  I want to learn new tools and new languages.  I want to learn new math and new tricks.  </p>

<h2 id="goals">Goals</h2>

<ul>
  <li>I want this blog to be a place where I post things that I’ve done, and invite other people to comment, question, share, improve, discuss, etc.  This should not be a place where I just comment on things other people have said, rant, or just post links.  </li>
  <li>I want most of my projects to find a way to do something cool with data.</li>
  <li>I don’t require all of my contributions to be original.  In fact, I think there’s a lot I could learn from implementing classic stuff that other people have pioneered; other people could also benefit from seeing a slowed-down tutorial on how some of the fancy things I want to learn about work.</li>
  <li>I’d like to have at least some of my posts be teaching/tutorial posts.  This may be a presumptuous goal; I’m a newcomer to a lot of the things I’m interested in, but I’ve been told alternatively that the best way to learn something is to a) implement it from scratch or b) teach it.  For somethings, I hope to do both</li>
</ul>

 -->
    
  </ul> 
</div>





          </div>
	</div>
	<div id="sidebar" class="yui-b">
	  <table><tr><td> 
		<ul> 
		  <li><a href="/index.html">Home</a></li> 
		  <li><a href="/blog/about.html">About</a></li> 
		  <li><a href="/blog/resume.html">Resume</a></li> 
		</ul> 
	  </td></tr></table> 
	</div>
      </div>      

    </div>
    <dstatic.flickr.com/5050/535iv>
      <!--  give credit where credit is due for fonts  -->
      <br><br>
      Font Credits:
      <font face="Linux Libertine Regular"><a href="http://www.linuxlibertine.org/index.php?id=2&L=1">linux libertine</a></font>&nbsp&nbsp
      <font face="Biolinum Regular"><a href="http://www.linuxlibertine.org/index.php?id=2&L=1">linux biolinum</a></font>&nbsp&nbsp
      <font face="skyhook"><a href="http://www.fontomtype.de/pages/2010/10/23/skyhookmono/">skyhook mono</a></font>
    </div>
  </body>
</html>
